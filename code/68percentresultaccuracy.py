# -*- coding: utf-8 -*-
"""68PercentResultAccuracy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QmbdZuzngkBSBDXor9eT9UWxenlPKpNQ
"""

# --- High-Accuracy: Subject-Specific Model with FBCSP and SVM ---
# This code correctly implements the subject-specific approach and adds
# advanced signal processing and a more robust classifier to reach high accuracy.

# Install necessary packages (do this first in a new Colab session)
!pip -q install mne scikit-learn numpy joblib pandas

import numpy as np
import mne
from mne.datasets import eegbci
from mne.decoding import CSP, Vectorizer
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.base import BaseEstimator, TransformerMixin
import os
import joblib
from sklearn.model_selection import StratifiedKFold
from mne.filter import filter_data
from joblib import Parallel, delayed

# ---- Config ----
MAX_SUBJECTS_TO_USE = 109
subjects_list = list(range(1, 110))[:MAX_SUBJECTS_TO_USE]
runs_to_use = [3, 7, 11]
tmin, tmax = 0.0, 4.0
sfreq_target = 100
n_csp = 6

# ---- Cache Directory ----
CACHE_DIR = './eeg_cache'
os.makedirs(CACHE_DIR, exist_ok=True)

# ---- Advanced Signal Processing & Classification Pipeline ----

class FilterBankCSP(BaseEstimator, TransformerMixin):
    """
    Implements Filter Bank Common Spatial Pattern (FBCSP) by
    running CSP on multiple frequency bands.
    """
    def __init__(self, n_components=6):
        self.n_components = n_components
        self.filters = []
        # Define multiple frequency bands for motor imagery
        # These are standard for MI-BCI research
        self.bands = [(8, 12), (13, 18), (18, 24), (24, 30), (8, 24), (12, 30)]
        self.csp_pipelines = []

    def fit(self, X, y=None):
        self.csp_pipelines = []
        for low, high in self.bands:
            # Filter the data for each band
            X_filtered = filter_data(X, sfreq_target, low, high, verbose=False)

            # Create a pipeline for each band
            pipeline = Pipeline([
                ('csp', CSP(n_components=self.n_components, reg=0.1, log=True, norm_trace=False)),
            ])
            pipeline.fit(X_filtered, y)
            self.csp_pipelines.append(pipeline)
        return self

    def transform(self, X):
        features = []
        for i, (low, high) in enumerate(self.bands):
            X_filtered = filter_data(X, sfreq_target, low, high, verbose=False)
            X_csp = self.csp_pipelines[i].transform(X_filtered)
            features.append(X_csp)

        # Concatenate features from all bands
        return np.concatenate(features, axis=1)

# ---- Data Loading & Caching Logic ----
def _load_subject_data(subject, runs):
    """
    Loads, preprocesses, and caches data for a single subject.
    This function is now called for one subject at a time.
    """
    print(f"Loading data for subject {subject}...")
    cache_path = os.path.join(CACHE_DIR, f'subj_{subject:03d}.pkl')

    if os.path.exists(cache_path):
        try:
            X, y = joblib.load(cache_path)
            print(f"Loaded cached data for subject {subject}")
            return X, y
        except Exception as e:
            print(f"Error loading cached data for subject {subject}: {e}. Recaching...")
            os.remove(cache_path) # Remove corrupted cache file

    try:
        fnames = eegbci.load_data(subject, runs, verbose=False)
        raws = [mne.io.read_raw_edf(f, preload=True, verbose=False) for f in fnames]
        raw = mne.concatenate_raws(raws, verbose=False)
        eegbci.standardize(raw)
        montage = mne.channels.make_standard_montage('standard_1005')
        raw.set_montage(montage, on_missing='ignore', verbose=False)
        raw.pick_types(eeg=True, verbose=False)
        raw.set_eeg_reference('average', projection=False, verbose=False)

        events, event_id = mne.events_from_annotations(raw, verbose=False)
        wanted = {'T1': event_id.get('T1'), 'T2': event_id.get('T2')}
        if None in wanted.values():
            return None, None

        epochs = mne.Epochs(raw, events, event_id=wanted, tmin=tmin, tmax=tmax,
                            baseline=None, preload=True, verbose=False)
        epochs.resample(sfreq_target, verbose=False)
        X = epochs.get_data()
        y_codes = epochs.events[:, 2]
        mapping = {wanted['T1']: 0, wanted['T2']: 1}
        y = np.vectorize(mapping.get)(y_codes)

        joblib.dump((X, y), cache_path)
        print(f"Cached data for subject {subject}")
        return X, y

    except Exception as e:
        print(f"Error processing subject {subject}: {e}")
        return None, None

# ---- Main Execution (Corrected and Enhanced) ----
if __name__ == '__main__':
    all_subject_accuracies = []

    print("Starting data download for all subjects. This may take a while...")
    _ = eegbci.load_data(subjects_list, runs_to_use, verbose=True)

    # This loop is the key to the new approach. We process one subject at a time.
    for subject_id in subjects_list:
        X, y = _load_subject_data(subject_id, runs_to_use)

        if X is not None:
            # Create a new pipeline for each subject
            # This is where we use FBCSP and SVM
            pipeline = Pipeline([
                ('fbcsp', FilterBankCSP(n_components=n_csp)),
                ('svm', SVC(kernel='linear', C=1)) # 'C' is a regularization parameter
            ])

            # Perform k-fold cross-validation on this single subject's data
            n_folds = 5
            skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)

            fold_accuracies = []

            for train_index, test_index in skf.split(X, y):
                X_train, X_test = X[train_index], X[test_index]
                y_train, y_test = y[train_index], y[test_index]

                # Fit and transform the data using the pipeline
                pipeline.fit(X_train, y_train)
                y_pred = pipeline.predict(X_test)

                acc = accuracy_score(y_test, y_pred)
                fold_accuracies.append(acc)

            subject_avg_acc = np.mean(fold_accuracies)
            all_subject_accuracies.append({'subject': subject_id, 'accuracy': subject_avg_acc})
            print(f"Subject {subject_id} average accuracy: {subject_avg_acc:.3f}")
        else:
            print(f"Skipping subject {subject_id} due to missing data.")

    # Calculate and display overall average accuracy
    if all_subject_accuracies:
        final_avg_acc = np.mean([d['accuracy'] for d in all_subject_accuracies])

        print("\n" + "="*50)
        print(f"Overall Average Accuracy Across All Subjects = {final_avg_acc:.3f}")
        print("="*50)

        # Save Results
        result_df = pd.DataFrame(all_subject_accuracies)
        result_df.to_csv('subject_specific_results.csv', index=False)
        print("Results saved to 'subject_specific_results.csv'")
    else:
        print("No valid subject data to process. Exiting.")